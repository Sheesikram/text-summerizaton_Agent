{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader,PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\OneDrive - FAST National University\\Desktop\\SheesLangchai\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Load the GROQ and OpenAI API keys\n",
    "os.environ['groq_api_key'] = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key = os.getenv(\"groq_api_key\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"Llama3-8b-8192\"\n",
    ")\n",
    "\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'Amanda baked cookies and will bring Jerry some tomorrow.', 'row': 0}, page_content=\"id: 13818513\\ndialogue: Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\\nsummary: Amanda baked cookies and will bring Jerry some tomorrow.\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loader=PyPDFDirectoryLoader(\"./us_census\")\n",
    "# loader = CSVLoader(file_path='Updated-Langchain\\huggingface\\sumsum\\samsum-train - Copy.csv', csv_args={\n",
    "#     'delimiter': ',',\n",
    "#     'quotechar': '\"',\n",
    "#     'fieldnames': ['id', 'dialogue', 'summary']\n",
    "# })\n",
    "# loader = CSVLoader(file_path='./sumsum/samsum-train - Copy.csv', source_column=\"summary\")\n",
    "loader = CSVLoader(\n",
    "    file_path='./sumsum/samsum-train - Copy.csv',\n",
    "    source_column=\"summary\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "data = loader.load()\n",
    "documents=loader.load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "final_documents=text_splitter.split_documents(documents)\n",
    "final_documents[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs=final_documents.create_document(documents)\n",
    "vectors = FAISS.from_documents(\n",
    "            final_documents,\n",
    "            embeddings\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=load_summarize_chain(llm=llm,chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=chain.run(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a concise summary of the text:\n",
      "\n",
      "The text describes a collection of casual conversations and updates among friends, covering various topics such as plans, personal issues, recommendations, reminders, and everyday life situations. The tone is lighthearted and casual, with friends sharing their thoughts, plans, and experiences with each other.\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for row 9: Matt asks Agnes out on a date to the Georgian restaurant in Kazimierz on Saturday at 6 pm, and she agrees to give it a try.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load data from CSV file\n",
    "loader = CSVLoader(file_path='./sumsum/samsum-train - Copy.csv', source_column=\"summary\", encoding=\"utf-8\")\n",
    "documents = loader.load()  # Load all rows as documents\n",
    "\n",
    "# Define a function to summarize a single line (row) from the CSV\n",
    "def summarize_csv_line(row_index: int):\n",
    "    # Ensure row_index is valid\n",
    "    if row_index < 0 or row_index >= len(documents):\n",
    "        raise ValueError(f\"Invalid row_index {row_index}. Must be between 0 and {len(documents) - 1}.\")\n",
    "    \n",
    "    # Extract the specific document\n",
    "    selected_document = [documents[row_index]]  # Wrap in a list for the chain\n",
    "\n",
    "    # Load the summarization chain\n",
    "    chain = load_summarize_chain(llm=llm, chain_type=\"map_reduce\")\n",
    "\n",
    "    # Run the summarization\n",
    "    summary = chain.run(selected_document)\n",
    "    return summary\n",
    "\n",
    "# Example: Summarize a single line from the CSV (e.g., row 3)\n",
    "row_index = 9  # Adjust this to the specific row you want to summarize\n",
    "summary = summarize_csv_line(row_index)\n",
    "\n",
    "print(f\"Summary for row {row_index}:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
